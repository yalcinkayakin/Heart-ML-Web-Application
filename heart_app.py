# -*- coding: utf-8 -*-
"""heart-app.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x9hz5xhTUm4LTHLvvs73V3UbRqYrcisZ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df =pd.read_csv('/content/heart1.csv')

df.head()

df.columns

df.columns.str.lower().str.replace('','')

df.columns = df.columns.str.lower().str.replace('','')

df.head()

df.dtypes

df =df.replace('?',0)

df.head()

df.dtypes

#sum(df.dtypes == 'object')
#(df.columns[df.dtypes =='int64']

df[['age',                        
'anaemia',                      
'creatinine_phosphokinase',      
'diabetes',                      
'ejection_fraction',             
'high_blood_pressure',           
'platelets',                   
'serum_creatinine',            
'serum_sodium',                  
'sex'         ,                  
'smoking'    ,                   
'time'           ,               
'death_event'     ,              
]].astype('int')

df.dtypes

df.count()

df.shape

df.isnull().sum()

df.describe()

target_label = {'Die': 1,'Live':0}

df['death_event'].value_counts()

df['death_event'].value_counts().plot(kind ='bar')

df['sex'].value_counts()

df['sex'].value_counts().plot(kind='bar')

df['age'].max()

df['age'].min()

labels = ["Less than 10","10-20","20-30","30-40","40-50","50-60","60-70","70 and more"]
bins= [0,10,20,30,40,50,60,70,80]
freq_df = df.groupby(pd.cut(df['age'],bins=bins,labels=labels)).size()

freq_df

frenq_df = freq_df.reset_index(name = 'count')

freq_df

frenq_df.plot(kind = 'bar')

labels = ['lt-10',"10-20","20-30","30-40","40-50","50-60","60-70","ge-70"]
fig1,ax1 = plt.subplots()
ax1.pie(freq_df['count'],labels=labels,autopct='1%.1f%%')
ax1.axis('equal')
plt.show()

sns.boxplot(df['age'])

q1 = df.quantile(0.25)
q3 = df.quantile(0.75)

IQR = q3-q1

IQR

(df < (q1 -1.5 * IQR)) | (df >(q3 + 1.5 * IQR))

df_no_outlier = df[~((df < (q1 -1.5 * IQR)) | (df >(q3 + 1.5 * IQR))).any(axis=1)]

df_no_outlier

print(df.shape)
print(df_no_outlier.shape)

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

x = df[['age',                  
  'anaemia',                      
'creatinine_phosphokinase',      
'diabetes',                      
'ejection_fraction',             
'high_blood_pressure',           
'platelets',                   
'serum_creatinine',            
'serum_sodium',                  
'sex'         ,                  
'smoking'    ,                   
'time'           ,               
]]

ylabel = df['death_event']

xfeatures

ylabel

skb =SelectKBest(score_func=chi2,k=10)
best_result = skb.fit(x,ylabel)

print('Sonuc;',best_result.scores_)

bf_02 = best_result.transform(x)

bf_02

feature_scores = pd.DataFrame(best_result.scores_,columns=['Feature_Scores'])

feature_column_names = pd.DataFrame(x.columns,columns=['Feature_name'])
best_feat_df = pd.concat([feature_scores,feature_column_names],axis=1)
best_feat_df

best_feat_df.nlargest(10,'Feature_Scores')

from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

logit = LogisticRegression()

rfe = RFE(estimator=LogisticRegression(),n_features_to_select=3)

rte_sonuc = rfe.fit(x,ylabel)

selected_features = pd.DataFrame(rte_sonuc.support_, columns=['Selected_Features'])
ranking_features = pd.DataFrame(rte_sonuc.ranking_, columns=['Ranking_Features'])

rte_feature_df = pd.concat([feature_column_names , selected_features,ranking_features],axis =1)

rte_feature_df

from sklearn.ensemble import ExtraTreesClassifier

et_clf = ExtraTreesClassifier()
et_clf.fit(x,ylabel)

print(et_clf.feature_importances_)

feature_imporance_df = pd.Series(et_clf.feature_importances_, index=x.columns)

feature_imporance_df

feature_imporance_df.nlargest(12).plot(kind='barh')

df.corr()

plt.figure(figsize=(20,10))
sns.heatmap(x.corr(),annot=True)
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

df.columns

x_train,x_test,y_train,y_test = train_test_split(x,ylabel,test_size=0.30,random_state=7)

x_train_b,x_test_b,y_train_b,y_test_b = train_test_split(x,ylabels,test_size=0.30,random_state=7)

logreg = LogisticRegression()
logreg.fit(x,ylabel)

logreg.score(x_test,y_test)

model_logit = LogisticRegression()
model_logit.fit(x_train_b,y_train_b)

model_logit.score(x_train_b,y_train_b)

clf = DecisionTreeClassifier()

clf.fit(x_train_b,y_train_b)

clf.score(x_test_b,y_test_b)

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)

knn.fit(x_train_b,y_train_b)

knn.score(x_test_b,y_test_b)

import joblib

model_file = open('LR_Heart_Result.pkl', 'wb')
joblib.dump(model_logit,model_file)
model_file.close()

model_file_knn = open('KNN_Heart_Result.pkl', 'wb')
joblib.dump(knn,model_file_knn)
model_file_knn.close()

model_file_clf = open('Decision Tree_Heart_Result.pkl', 'wb')
joblib.dump(clf,model_file_clf)
model_file_knn.close()

from IPython.display import Image
from sklearn import tree
import pydotplus

feature_names_best = x.columns

target_names = ["Die","Live"]

dot_data = tree.export_graphviz(clf,out_file=None,feature_names=feature_names_best,class_names=target_names)

graph = pydotplus.graph_from_dot_data(dot_data)

Image(graph.create_png())

import eli5

class_names = ["Die","Live"]

from sklearn.metrics import confusion_matrix

y_pred = model_logit.predict(x_test_b)

accuracy_score(y_test,y_pred)

confusion_matrix(y_test,y_pred)

from sklearn.metrics._plot.confusion_matrix import plot_confusion_matrix
plot_confusion_matrix(model_logit,x_test_b,y_test_b)

from sklearn.metrics import classification_report

print(classification_report(y_test,y_pred,target_names=class_names))

df.to_csv("clean_heart_dataset.csv",index=False)

freq_df.to_csv("freq_df_heart_dataset.csv")



















